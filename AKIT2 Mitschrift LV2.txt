#Wir machen einfach nur Zufallswerte und schauen ob wie einen Zusammenhang erreichen.
x = rnorm(n = 300)
y = rnorm(n = 300)
cor(x, y)
m = lm (y ~ x)
summary(m)

#Ergebniss - Wir schaffen es easy einen Zusammenhang mit Zufallszahlen.
Residuals:
    Min      1Q  Median      3Q     Max 
-2.6861 -0.7416  0.0158  0.6459  3.3985 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)  
(Intercept) -0.04284    0.06060  -0.707   0.4801  
x           -0.12414    0.05744  -2.161   0.0315 * //1x Stern heißt es ist signifikat, 2x Stern Förderung einreichen, 3x heißt Nobelpreis^^
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.049 on 298 degrees of freedom
Multiple R-squared:  0.01543,	Adjusted R-squared:  0.01213 
F-statistic:  4.67 on 1 and 298 DF,  p-value: 0.03148

#Weiterer Versuch
model2 = lm(gesamt ~ gruppe + frage9 + frage10, data=kry)
summary(model2)
plot(kry$gesamt, resid(model2))
plot(model2, which=1) #Wäre optimalerweise ein gerader Strich - heißt Varianz ist linear.
hist(resid(model2))

#car ist ein zusätzliches Packet mit zusätzlichen Tools zu verwenden (zB qqp)
library(car)
qqp(model2) #Wichtiger als Befehl in Zeile 28 - Hier sieht man Besser die Varianz.

vif(model2)
# variance inflation factor - wenn Werte zweistellig werden dann ist das sehr schlecht. Mehr als 5 ist nicht hübsch geht aber noch.
# Um so niedrieger die Zahlen sind desto weniger hängen sie voneinander ab.

plot(model2, which=4)
# Cockdistace sagt aus wieviel die einzelenen Werte von unserer Schaukel entfernt sind.

plot(model2, which=5)
# Sollte in den roten Linien bleiben (0,5)

outlierTest(model2)

No Studentized residuals with Bonferonni p < 0.05
Largest |rstudent|:
   rstudent unadjusted p-value Bonferonni p
11 2.024271           0.053751           NA
# Wenn No am Anfang steht dann passt alles und wir haben keine Werte die unsere Ergebnisse verziehen.

model3 = lm(gesamt ~ gruppe + frage9 + frage10, data=kry[-17,])
# Nehmen hier Wert mit -17 raus und schauen wie sich die Werte verändern.
summary(model3)
summary(model2)



# Neue Daten
cat = read.csv('C:\\Users\\Dominik\\Downloads\\cats\\cat-experiment-4.csv')
summary(cat)

mean(cat$response[cat$word=='noun1'])
mean(cat$response[cat$word=='noun2'])
mean(cat$response[cat$word=='noun3'])
mean(cat$response[cat$word=='noun4'])
mean(cat$response[cat$word=='cat_name'])

catmodel = lm(response ~ word, data=cat)
summary(catmodel)




# Neues Beispiel
df = read.csv('C:\\Users\\Dominik\\Downloads\\housing-prices-ge19.txt')
m1 = lm(Price ~ Age + Land.Value + Living.Area + Pct.College + Bedrooms, data=df)
summary(m1)

plot(m1, which=1)

library(car)
qqp(m1) # sieht nicht gut aus oben hin
vif(m1)
plot(m1, which=4)
plot(m1, which=5)


hist(df$Price)

df$price.log = log10(df$Price) # deswegen gleichen wir es mit einem log aus
hist(df$price.log)

m2 = lm(price.log ~ Age + Land.Value + Living.Area + Pct.College + Bedrooms, data=df)
summary(m2)

qqp(m2) # sieht nun besser aus da price.log verwendet wird
outlierTest(m2) # Mehrere Werte nahe an 10 ist schlecht - Ausreißer

diff_y = 10^(-8.648e-04) # Heißt wenn wir um ein x rüber gehen steigt es um 0.998 im y.
10000*diff_y # nach 1 Jahr
10000*diff_y*diff_y # nach 2 Jahren
10000*(diff_y^7) # nach 7 Jahren ist die Wohnung so viel wert.
# Wichtig für Prüfung!

# Für Bedrooms bedeutet das 
bed_diff = 10*coef(m2)[6]
100000*(bed_diff^2)