exp(predict(model, newdata = data.frame(Function.point.log = 100),interval = "confidence"))
4.218092e+44*100
4.218092e+44*100
#Mit Log:
exp(predict(model, newdata = data.frame(Function.point.log = 100, type='response')))
#Mit Log:
predict(model, newdata = data.frame(Function.point.log = 100, type='response'))
plot(body$Function.point.log, body$Work.hours.log)
#4
model = lm(Work.hours.log ~ Function.point.log, data = body)
koeff = coef(model)
abline(a=koeff[1], b=koeff[2], col = "blue")
Work.hours.log
body$Work.hours.log
body$Function.point.log
#1
body = read.csv('C:\\Users\\Dominik\\Downloads\\software-estimation.csv')
#2
hist(body$Function.point)
hist(body$Work.hours)
#3
plot(body$Function.point, body$Work.hours)
#Log anwenden um Punkte aus linken unterer Ecke zu bekommen
model.log=lm(log(Work.hours) ~ log(Function.point), data = body)
hist(resid(model.log))
plot(log(body$Function.point), log(body$Work.hours)
plot(log(body$Function.point),log(body$Work.hours))
#4 mit Log:
#Log anwenden um Punkte aus linken unterer Ecke zu bekommen
model.log=lm(log(Work.hours) ~ log(Function.point), data = body)
hist(resid(model.log))
plot(log(body$Function.point),log(body$Work.hours))
koeff.log = coef(model.log)
exp(koeff.log)
exp(confint(model.log))
abline(model.log)
#Mit Log:
exp(predict(model.log, newdata = data.frame(Function.point=100),type="response"))
#1249.634
exp(predict(model.log, newdata = data.frame(Function.point=200),type="response"))
#2503.406
exp(predict(model.log, newdata = data.frame(Function.point=400),type="response"))
#5015.103
exp(predict(model.log, newdata = data.frame(Function.point=800),type="response"))
#10046.81
exp(predict(model.log, newdata = data.frame(Function.point=1600),type="response"))
#20126.9
exp(predict(model.log, newdata = data.frame(Function.point=400),type="response"))
#20126.9
exp(predict(model.log, newdata = data.frame(Function.point=3200),type="response"))
# Laden Sie als erstes das Body-Datenset (setwd() nicht vergessen bzw. Pfad anpassen)
body = read.csv("C:\\Users\\Dominik\\Downloads\\body-dimensions.csv")
# 1) Schauen Sie sich das Histogramm folgender Variable an:
# - Knee.diameter
hist(body$Knee.diameter)
# - Forearm.girth
hist(body$Forearm.girth)
# - Weight
hist(body$Weight)
# 2) Berechnen Sie mean() und sd() der drei Variable
describe(body$Knee.diameter)
# 2) Berechnen Sie mean() und sd() der drei Variable
Describe(body$Knee.diameter)
# 2) Berechnen Sie mean() und sd() der drei Variable
describe(body$Knee.diameter)
# 2) Berechnen Sie mean() und sd() der drei Variable
library(psych)
describe(body$Knee.diameter)
describe(body$Forearm.girth)
describe(body$Weight)
# 3) Stellen Sie ein Regressionsmodell auf:
# "Gewicht als abhängige Variable der anderen beiden Variable"
# und interpretieren Sie das Modell:
model = lm(Weight ~ Knee.diameter + Forearm.girth, data = body)
summary(model)
# Welcher der beiden Variable hat mehr Einfluss auf das Gewicht?
library(car)
Anova(model)
drop1(model)
# z-Skalierung
# 4) Berechnen Sie eine neue Spalte body$knee.diameter.z
# und eine neue Spalte body$forearm.girth.z
# in dem Sie zuerst den Mittelwert der jeweiligen Spalte abziehen und
# dann durch die Standardabweichung der jeweiligen Spalte dividieren
body$knee.diameter.z = body$knee.diameter - mean(body$knee.diameter) / sd(body$knee.diameter)
# z-Skalierung
# 4) Berechnen Sie eine neue Spalte body$knee.diameter.z
# und eine neue Spalte body$forearm.girth.z
# in dem Sie zuerst den Mittelwert der jeweiligen Spalte abziehen und
# dann durch die Standardabweichung der jeweiligen Spalte dividieren
body$Knee.diameter.z = body$Knee.diameter - mean(body$Knee.diameter) / sd(body$Knee.diameter)
body$Forearm.girth.z = body$Forearm.girth - mean(body$Forearm.girth) / sd(body$Forearm.girth)
# 5) Schauen Sie sich das Histogramm der beiden Variable an
# und vergleichen Sie es mit den Histogrammen der Original-Variablen.
# Berechnen Sie auch Mittelwert und Standardabweichung
# Welche Auswirkung hatte die Transformation?
par(mfrow=c(2,2))
hist(body$Knee.diameter)
hist(body$Knee.diameter.z)
hist(body$Forearm.girth)
hist(body$Forearm.girth.z)
# 6) Zeichnen Sie folgende Scatterplots
# a) Knee.diameter vs. Weight
plot(body$Knee.diameter, body$Weight)
# b) knee.diameter.z vs. Weight
plot(body$Knee.diameter.z, body$Weight)
# c) Forearm.girth vs. Weight
plot(body$Forearm.girth, body$Weight)
# d) forearm.girth.z vs. Weight
plot(body$Forearm.girth.z, body$Weight)
# e) Knee.diameter vs. knee.diameter.z
plot(body$Knee.diameter, body$Knee.diameter.z)
# f) Forearm.girth vs. forearm.girth.z
plot(body$Forearm.girth, body$Forearm.girth.z)
# 7) Stellen Sie ein zweites lineares Modell auf:
# "Gewicht als abhängige Variable der beiden z-transformierten Variable"
# und interpretieren Sie das Modell:
model.z = lm(Weight ~ Knee.diameter.z + Forearm.girth.z, data = body)
summary(model.z)
body$Forearm.girth.z = body$Forearm.girth - mean(body$Forearm.girth) / sd(body$Forearm.girth)
body$Forearm.girth.z
body$Forearm.girth.z = body$Forearm.girth - mean(body$Forearm.girth) / sd(body$Forearm.girth)
# f) Forearm.girth vs. forearm.girth.z
plot(body$Forearm.girth, body$Forearm.girth.z)
body$Forearm.girth.z = scale(body$Forearm.girth)
# z-Skalierung
# 4) Berechnen Sie eine neue Spalte body$knee.diameter.z
# und eine neue Spalte body$forearm.girth.z
# in dem Sie zuerst den Mittelwert der jeweiligen Spalte abziehen und
# dann durch die Standardabweichung der jeweiligen Spalte dividieren
body$Knee.diameter.z = scale(body$Knee.diameter)
hist(body$Knee.diameter)
# 5) Schauen Sie sich das Histogramm der beiden Variable an
# und vergleichen Sie es mit den Histogrammen der Original-Variablen.
# Berechnen Sie auch Mittelwert und Standardabweichung
# Welche Auswirkung hatte die Transformation?
par(mfrow=c(2,2))
hist(body$Knee.diameter)
hist(body$Knee.diameter.z)
hist(body$Forearm.girth)
hist(body$Forearm.girth.z)
# 7) Stellen Sie ein zweites lineares Modell auf:
# "Gewicht als abhängige Variable der beiden z-transformierten Variable"
# und interpretieren Sie das Modell:
model.z = lm(Weight ~ Knee.diameter.z + Forearm.girth.z, data = body)
summary(model.z)
# 8) Nehmen Sie den ersten Fall aus dem Datensatz und sagen Sie das Gewicht vorher anhand
# a) des ersten Modells - und der unskalierten Variablen
predict(model, newdata = data.frame(fall1), type = 'response')
# b) des skalierten Modells - auf Basis der z-Werte
# Ãberdenken Sie nochmal Ihre Interpretation der Koeffizienten.
# Was bedeutet eine Ãnderung von +-1 bei den Variablen?
# Hinweise:
# - mit coef() erhalten Sie die Koeffizienten des Modells
# - Ergebnis sollte beide Male ca. 69.3kg ergeben
fall1 = body[1,]
# 8) Nehmen Sie den ersten Fall aus dem Datensatz und sagen Sie das Gewicht vorher anhand
# a) des ersten Modells - und der unskalierten Variablen
predict(model, newdata = data.frame(fall1), type = 'response')
#69.29447
# b) des skalierten Modells - auf Basis der z-Werte
predict(model.z, newdata = data.frame(fall1), type = 'response')
# 9) Schauen Sie sich für das z-Modell die erklärte Varianz an und die Anova-Rechnung an.
# Unterscheiden sich die Werte für das Modell?
Anova(model)
drop1(model)
# 9) Schauen Sie sich für das z-Modell die erklärte Varianz an und die Anova-Rechnung an.
# Unterscheiden sich die Werte für das Modell?
Anova(model.z)
drop1(model.z)
# 10) z-Skalieren Sie nun auch das Gewicht selbst (als body$weight.z)
# Benützen Sie statt manueller Umrechnung  die scale()-Funktion.
body$Weight.z = scale(body$Weight)
# Schauen Sie sich wieder Histogramm, Mittelwert und Standardabweichung an.
hist(body$Weight)
hist(body$Weight.z)
describe(body$Weight)
describe(body$Weight)
describe(body$Weight.z)
# Setzen Sie dann ein neues Modell auf und interpretieren Sie wieder die Koeffizienten.
model.z2 = lm(Weight.z ~ Knee.diameter.z + Forearm.girth.z, data = body)
summary(model.z2)
summary(model.z)
# Wenn ich eine Forearm.girth=26 und eine Knee.diameter=18.8 habe, welches Gewicht sagt das Modell vorher?
# (Einige Umrechnungen sind notwendig)
knee.z = (18.8-mean(body$Knee.diameter))/sd(body$Knee.diameter)
Forearm.z = (26-mean(body$Forearm.girth))/sd(body$Forearm.girth)
predict(model.z2, newdata = data.frame(Knee.diameter.z=knee.z, Forearm.girth.z=Forearm.z),type = 'response')
# z-Skalierung
# 4) Berechnen Sie eine neue Spalte body$knee.diameter.z
# und eine neue Spalte body$forearm.girth.z
# in dem Sie zuerst den Mittelwert der jeweiligen Spalte abziehen und
# dann durch die Standardabweichung der jeweiligen Spalte dividieren
body$Knee.diameter.z = (body$Knee.diameter-mean(body$Knee.diameter))/sd(body$Knee.diameter)
body$Forearm.girth.z = (body$Forearm.girth-mean(body$Forearm.girth))/sd(body$Forearm.girth)
# Setzen Sie dann ein neues Modell auf und interpretieren Sie wieder die Koeffizienten.
model.z2 = lm(Weight.z ~ Knee.diameter.z + Forearm.girth.z, data = body)
summary(model.z)
# Wenn ich eine Forearm.girth=26 und eine Knee.diameter=18.8 habe, welches Gewicht sagt das Modell vorher?
# (Einige Umrechnungen sind notwendig)
knee.z = (18.8-mean(body$Knee.diameter))/sd(body$Knee.diameter)
Forearm.z = (26-mean(body$Forearm.girth))/sd(body$Forearm.girth)
predict(model.z2, newdata = data.frame(Knee.diameter.z=knee.z, Forearm.girth.z=Forearm.z),type = 'response')
# Aufgabenstellung:
# Wir wollen in unserem Netzwerk den Jitter von IP-Packeten reduzieren.
# Wir testen dazu das Verhalten eines neuen Routers im Vergleich zum alten.
# Wir haben kein Vorwissen, ob der neue Router schlechter oder besser ist.
# Im Datenfile finden Sie 300 Messpunkte (in ms):
# 150 Jitter-Werte vom alten, 150 Jitter-Werte vom neuen Router.
router = read.csv("C:\\Users\\Dominik\\Downloads\\network.csv")
# 1) Berechnen Sie, welchen Effekt wir mit 85% Wahrscheinlichkeit messen können.
sd.split(sd(router$jitter[router$gruppe=="neu"])+sd(router$jitter[router$gruppe=="alt"]))/2
# 1) Berechnen Sie, welchen Effekt wir mit 85% Wahrscheinlichkeit messen können.
sd_split(sd(router$jitter[router$gruppe=="neu"])+sd(router$jitter[router$gruppe=="alt"]))/2
# 1) Berechnen Sie, welchen Effekt wir mit 85% Wahrscheinlichkeit messen können.
sd.split=(sd(router$jitter[router$gruppe=="neu"])+sd(router$jitter[router$gruppe=="alt"]))/2
mean_split=(mean(router$jitter[router$gruppe=="neu"])-mean(router$jitter[router$gruppe=="alt"]))
d=mean.split/sd.split
# Aufgabenstellung:
# Wir wollen in unserem Netzwerk den Jitter von IP-Packeten reduzieren.
# Wir testen dazu das Verhalten eines neuen Routers im Vergleich zum alten.
# Wir haben kein Vorwissen, ob der neue Router schlechter oder besser ist.
# Im Datenfile finden Sie 300 Messpunkte (in ms):
# 150 Jitter-Werte vom alten, 150 Jitter-Werte vom neuen Router.
router = read.csv("C:\\Users\\Dominik\\Downloads\\network.csv")
# 1) Berechnen Sie, welchen Effekt wir mit 85% Wahrscheinlichkeit messen können.
sd.split=(sd(router$jitter[router$gruppe=="neu"])+sd(router$jitter[router$gruppe=="alt"]))/2
mean.split=(mean(router$jitter[router$gruppe=="neu"])-mean(router$jitter[router$gruppe=="alt"]))
d=mean.split/sd.split
library(pwr)
pwr.t.test(d=d, sig.level = 0.05, power = 0,85, alternative = "less")
pwr.t.test(d=d, sig.level = 0.05, power = 0.85, alternative = "less")
d=mean.split/sd.split
d
# 3) Wenn wir uns in 9 von 10 FÃ¤llen richtig entscheiden wollen, ist der neue Router dann
#    besser bzw. immer noch besser?
pwr.t.test(n=300, sig.level = 0.1, power = 0.85, alternative = "less")
# Aufgabenstellung (analog zu Übung 03b-1):
# Wir wollen in unserem Netzwerk den Jitter von IP-Packeten reduzieren.
# Wir testen dazu das Verhalten eines neuen Routers im Vergleich zum alten.
# Im Datenfile finden Sie Messpunkte zu altem und neuem Router.
# Damit sich die Umstellung lohnt, muss der neue Router mindestens 5ms kleineren Jitter haben.
# Wir wollen zumindest einen Unterschied von 2ms zuverlässig (=zu 90%) messen können.
router = read.csv("C:\\Users\\Dominik\\Downloads\\network2.csv")
# Aufgabenstellung (analog zu Übung 03b-1):
# Wir wollen in unserem Netzwerk den Jitter von IP-Packeten reduzieren.
# Wir testen dazu das Verhalten eines neuen Routers im Vergleich zum alten.
# Im Datenfile finden Sie Messpunkte zu altem und neuem Router.
# Damit sich die Umstellung lohnt, muss der neue Router mindestens 5ms kleineren Jitter haben.
# Wir wollen zumindest einen Unterschied von 2ms zuverlässig (=zu 90%) messen können.
router = read.csv("C:\\Users\\Dominik\\Downloads\\network2.csv")
# 1) Bestimmen Sie, wie viele Samples Sie brauchen.
library(pwr)
pwr.t.test(d=router$jitter[router$gruppe=="alt"], sig.level = 0.05, power = 0.9, alternative = "less")
pwr.t.test(d=mean(router$jitter[router$gruppe=="alt"]), sig.level = 0.05, power = 0.9, alternative = "less")
pwr.t.test(d=mean(router$jitter[router$gruppe=="alt"])-mean(router$jitter[router$gruppe=="neu"]), sig.level = 0.05, power = 0.9, alternative = "less")
d=mean(router$jitter[router$gruppe=="alt"])-mean(router$jitter[router$gruppe=="neu"])
pwr.t.test(d=d, sig.level = 0.05, power = 0.9, alternative = "less")
sd.split=(sd(router$jitter[router$gruppe=="neu"])+sd(router$jitter[router$gruppe=="alt"]))/2
mean.split=(mean(router$jitter[router$gruppe=="neu"])-mean(router$jitter[router$gruppe=="alt"]))
d=mean.split/sd.split
pwr.t.test(d=d, sig.level = 0.05, power = 0.9, alternative = "less")
# Aufgabenstellung (analog zu Übung 03b-1):
# Wir wollen in unserem Netzwerk den Jitter von IP-Packeten reduzieren.
# Wir testen dazu das Verhalten eines neuen Routers im Vergleich zum alten.
# Im Datenfile finden Sie Messpunkte zu altem und neuem Router.
# Damit sich die Umstellung lohnt, muss der neue Router mindestens 5ms kleineren Jitter haben.
# Wir wollen zumindest einen Unterschied von 2ms zuverlässig (=zu 90%) messen können.
router = read.csv("C:\\Users\\Dominik\\Downloads\\network2.csv")
# 1) Bestimmen Sie, wie viele Samples Sie brauchen.
library(pwr)
pwr.t.test(d=2/sd(router$jitter), sig.level = 0.05, power = 0.9, alternative = "greater")
# 2) Holen Sie sich exakt diese Anzahl an Samples zufÃ¤llig aus dem Datensatz. (Siehe Tipp 3)
#    Verwenden Sie set.seed(1234) bevor Sie das Zufallssample ziehen.
library(dplyr)
set.seed(1234)
# 1) Bestimmen Sie, wie viele Samples Sie brauchen.
hist(router$jitter)
plot(router$gruppe, router$jitter)
pwr.t.test(d=2/round(sd(router$jitter)), sig.level = 0.05, power = 0.9, alternative = "greater")
samples = sample_n(tbl = router, size = 430)
show(samples$gruppe)
samples$gruppe = as.numeric(samples$gruppe)
show(samples$gruppe)
hist(samples$gruppe)
# 3) Stellen Sie ein Modell mit dem ausgewählten Sample auf und interpretieren Sie das Ergebnis.
model = lm(jitter ~ gruppe, data = samples)
summary(model)
set.seed(1234)
samples = sample_n(tbl = router, size = 430)
show(samples$gruppe)
samples$gruppe = as.numeric(samples$gruppe)
# 3) Stellen Sie ein Modell mit dem ausgewählten Sample auf und interpretieren Sie das Ergebnis.
model = lm(jitter ~ gruppe, data = samples)
summary(model)
samples = sample_n(tbl = router, size = 429)
show(samples$gruppe)
samples$gruppe = as.numeric(samples$gruppe)
# 3) Stellen Sie ein Modell mit dem ausgewählten Sample auf und interpretieren Sie das Ergebnis.
model = lm(jitter ~ gruppe, data = samples)
summary(model)
# Laden Sie als erstes das Body-Datenset (setwd() nicht vergessen bzw. Pfad anpassen)
body = read.csv("C:\\Users\\Dominik\\Downloads\\body-dimensions.csv")
# 3) Stellen Sie ein Regressionsmodell auf:
# "Gewicht als abhängige Variable der anderen beiden Variable"
# und interpretieren Sie das Modell:
model = lm(Weight ~ Knee.diameter + Forearm.girth, data = body)
summary(model)
# Welcher der beiden Variable hat mehr Einfluss auf das Gewicht?
library(car)
Anova(model) #Reihenfolge der Variablen im Modell beeinflusst Ergebniss?
drop1(model)
# Neues Beispiel
# Anwendung der Bayes- Regel
theta = seq(0,1, length.out = 100)
likley = dbinom(60, size = 100, prob = theta)
prior = dbeta(theta, 3, 3)
# wie sieht der prior aus
plot(theta, prior, type = 'l')
# 1) Bei einer Serie von Münzwürfen erhalten wir 3x Kopf in 10 Würfen.
#    Zeichnen Sie ein Diagramm für den Posterior, wenn ein uniformer
#    Prior verwendet wird und zeichnen Sie das 75%-HDI ein.
#    Tipp: Sehen Sie sich Ähnliche Berechnungen im Source-Code
#          des Arbeitsblatts an. Verwenden Sie aber 500 Punkte
#          und type="l" für den Plot.
theta = seq(0, 1, length.out = 500)
prior = rep(1/500, 500) #1 = 100%. Diese teilen wir gleichmößig auf 500 Werte auf.
likelihood = dbinom(3, 10, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
plot(theta, posterior, type = "l", col = "green")
showHDI(theta, posterior, 0.75)
# AKIT2, Arno Hollosi
# Übung: Bayes
library(akit2)
showHDI(theta, posterior, 0.75)
likelihood = dbinom(27, 40, theta)
# 2) Nehmen Sie den Posterior aus (1) als neuen Prior und
#    berechnen Sie die Posterior-Verteilung für 27x Kopf bei 40 Würfen.
#    Diagramm + 75%-HDI
prior = posterior
likelihood = dbinom(27, 40, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
plot(theta, posterior, type = "l", col = "blue")
p
showHDI(theta, posterior, 0.75)
# 3) Vergleichen Sie das so erzeugte Diagramm mit folgender Serie:
#    uniformer Prior, N=50, z=30
#    Welchen Schluss ziehen Sie daraus?
prior = rep(1/500, 500)
likelihood = dbinom(30, 40, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
plot(theta, posterior, type = "l", col = "yellow")
showHDI(theta, posterior, 0.75)
# 3) Vergleichen Sie das so erzeugte Diagramm mit folgender Serie:
#    uniformer Prior, N=50, z=30
#    Welchen Schluss ziehen Sie daraus?
prior = rep(1/500, 500)
likelihood = dbinom(30, 50, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
plot(theta, posterior, type = "l", col = "yellow")
showHDI(theta, posterior, 0.75)
likelihood = dbinom(12, 50, theta)
# 4) Vergleichen Sie folgende zwei Ergebnisse:
# a) Zuerst uniformer Prior, N=20, z=12; dann
#    resultierenden Posterior als Prior nützen für N=30, z=20
# b) Zuerst uniformer Prior, N=30, z=20; dann
#    resultierenden Posterior als Prior nützen für N=20, z=12
# Welchen Schluss ziehen Sie daraus?
# Warum entsteht dieser Zusammenhang?
prior = rep(1/500, 500)
likelihood = dbinom(12, 20, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
prior = posterior
likelihood = dbinom(20, 30, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
plot(theta, posterior, type = "l", col = "darkgreen")
showHDI(theta, posterior, 0.75)
prior = rep(1/500, 500)
likelihood = dbinom(20, 30, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
prior = posterior
likelihood = dbinom(12, 20, theta)
posterior = prior * likelihood
plot(theta, posterior, type = "l", col = "darkgreen")
showHDI(theta, posterior, 0.75)
plot(theta, posterior, type = "l", col = "darkgreen")
showHDI(theta, posterior, 0.75)
prior = rep(1/500, 500)
likelihood = dbinom(20, 30, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
prior = posterior
likelihood = dbinom(12, 20, theta)
posterior = prior * likelihood
plot(theta, posterior, type = "l", col = "darkgreen")
showHDI(theta, posterior, 0.75)
prior = rep(1/500, 500)
likelihood = dbinom(20, 30, theta)
posterior = prior * likelihood
likelihood = dbinom(20, 30, theta)
# 1) Bei einer Serie von Münzwürfen erhalten wir 3x Kopf in 10 Würfen.
#    Zeichnen Sie ein Diagramm für den Posterior, wenn ein uniformer
#    Prior verwendet wird und zeichnen Sie das 75%-HDI ein.
#    Tipp: Sehen Sie sich Ähnliche Berechnungen im Source-Code
#          des Arbeitsblatts an. Verwenden Sie aber 500 Punkte
#          und type="l" für den Plot.
theta = seq(0, 1, length.out = 500) #Wahrscheinlichkeit das ein bestimmter Wert eintritt
likelihood = dbinom(20, 30, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
prior = posterior
likelihood = dbinom(12, 20, theta)
posterior = prior * likelihood
plot(theta, posterior, type = "l", col = "darkgreen")
showHDI(theta, posterior, 0.75)
prior = rep(1/500, 500)
likelihood = dbinom(12, 20, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
prior = posterior
likelihood = dbinom(20, 30, theta)
posterior = prior * likelihood
plot(theta, posterior, type = "l", col = "darkgreen")
showHDI(theta, posterior, 0.75)
# AKIT2, Arno Hollosi
# Übung: Bayes
library(akit2)
prior = rep(1/500, 500)
likelihood = dbinom(20, 30, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
prior = posterior
likelihood = dbinom(12, 20, theta)
posterior = prior * likelihood
plot(theta, posterior, type = "l", col = "darkgreen")
showHDI(theta, posterior, 0.75)
prior = rep(1/500, 500)
likelihood = dbinom(30, 50, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
plot(theta, posterior, type = "l", col = "yellow")
showHDI(theta, posterior, 0.75)
# 4) Vergleichen Sie folgende zwei Ergebnisse:
# a) Zuerst uniformer Prior, N=20, z=12; dann
#    resultierenden Posterior als Prior nützen für N=30, z=20
# b) Zuerst uniformer Prior, N=30, z=20; dann
#    resultierenden Posterior als Prior nützen für N=20, z=12
# Welchen Schluss ziehen Sie daraus?
# Warum entsteht dieser Zusammenhang?
prior = rep(1/500, 500)
likelihood = dbinom(12, 20, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
prior = posterior
likelihood = dbinom(20, 30, theta)
posterior = prior * likelihood
plot(theta, posterior, type = "l", col = "darkgreen")
showHDI(theta, posterior, 0.75)
showHDI(theta, posterior, 0.75)
posterior = likelihood * prior
posterior = posterior / sum(posterior)
prior = posterior
likelihood = dbinom(20, 30, theta)
posterior = posterior / sum(posterior)
plot(theta, posterior, type = "l", col = "darkgreen")
showHDI(theta, posterior, 0.75)
posterior = prior * likelihood
prior = rep(1/500, 500)
likelihood = dbinom(20, 30, theta)
posterior = likelihood * prior
posterior = posterior / sum(posterior)
prior = posterior
likelihood = dbinom(12, 20, theta)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
plot(theta, posterior, type = "l", col = "darkgreen")
showHDI(theta, posterior, 0.75)
# 5) Gegeben sei die Datenreihe y ~ Poisson(1000).
#    Die Poisson-Verteilung wird hÃ¤ufig für ganzzahlige Ereignisse
#    (z.B. Anzahl Goldmedaillien, Anzahl Unfälle etc.) verwendet.
#    Berechnen Sie mit Hilfe von Bayes die Posterior-Verteilung
#    und 95%-HDI für den Mittelwert der Population auf Basis der
#    Datenreihe mit uniformen Prior für den Bereich 950:1050.
#    Die Likelihood-Funktion für eine Poisson-Verteilung ist als
#    Hilfestellung vorgegeben.
set.seed(1234)
daten = rpois(30, 1000)
pois.likelihood = function(data, parameter) {
dist = rep(1, length(parameter))
for (y in data) {
# die einzelnen Wahrscheinlichkeiten multiplizieren sich auf,
# weil die einzelnen Messwerte unabhÃ¤ngig voneinander sind
dist = dist * dpois(y, parameter)
}
return(dist)
}
lambda = 950:1050
prior = rep(1/101, 101)
likelihood = pois.likelihood(daten, lambda)
posterior = prior * likelihood
posterior = posterior / sum(posterior)
plot(lambda, posterior, type = "l", col = "darkgreen")
showHDI(theta, posterior, 0.75)
showHDI(theta, posterior, 0.95)
showHDI(lambda, posterior, 0.95)
