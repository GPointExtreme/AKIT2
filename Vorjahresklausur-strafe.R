# AKIT2 SS18, Hauptklausur, 15.6.2018
library(ggplot2)
library(car)
library(corrplot)
library(effects)
library(pwr)
library(ROCR)
library(runjags)
library(coda)
rjags::load.module("glm")
library(akit2)

df <- read.csv('C:\\Users\\Dominik\\Downloads\\strafe.csv')
# Referenz-Gruppe Ã¤ndern
df$race = relevel(df$race, ref = 'Caucasian')
df$sex = relevel(df$sex, ref = 'Male')


# In Amerika werden Algorithmen eingesetzt, um vorherzusagen, ob eine straffÃ¤llige Person
# wieder rückfällig wird. Diese Algorithmen liefern einen Risiko-Wert, der zum Großteil
# auf Basis eines Fragebogens errechnet wird. Es stellt sich die Frage, ob diese
# Algorithmen eine versteckte Tendenz haben, ob sie also einzelne Personengruppen 
# benachteiligen.
# 
# Der Datensatz stammt aus einem einzelnen Bundesstaat der USA und enthÃ¤lt neben
# einigen Angaben auch, ob eine Person tatsÃ¤chlich rÃ¼ckfÃ¤llig geworden ist. Datenfelder:
#
# - age ... Alter der Person in Jahren
# - risk_score ... Risiko-Wert (1-10), ob eine Person rÃ¼ckfÃ¤llig wird (berechnet von Algorithmus)
# - priors_count ... Anzahl an Vorstrafen
# - sex ... Geschlecht
# - is_recid ... ob eine Person im Zeitraum von 2 Jahren rÃ¼ckfÃ¤llig geworden ist (yes) oder nicht (no)
# - charge_degree ... Schwere der begangenen Straftat
# - race ... Rasse (aus amerikanischer Sicht)


# Schritt 1: Erstellen Sie beschreibende Statistiken zu wichtigsten Werten des Datensatzes,
#            vor allem in Hinblick auf Rasse, Geschlecht, Risikowert und Rückfallquote.
#            Zu welchen ersten Hypothesen gelangen Sie?
summary(df)
describe(df)
#age: mean 35, min 18, max 96
#sex: male 4997, female 1175
#priors_count: Durschnittlicher gefangener hat 5 Vorstrafen.
#risk_score: Liegt durchschnittlich bei 4.4 von 10.
#is_recid: ca. 50% werden wieder Straffällig in den nächsten 2 Jahren.

table(df$race)
#Meisten sind:
#Caucasian:         2103
#African-American:  3175
#Hispanic:          509
#Alle anderen sind kleiner als Hispanic.

############################################################

#Rasse vs. Rückfällig
plot(df$race, df$is_recid)
#Rüclfällig wurden:
#Caucasian:         ca. 40%
#African-American:  ca. 60%
#Hispanic:          ca. 40%
#Asia:              ca. 35%
#Native American:   ca. 65%
#Other:             ca. 40%

#Rasse vs. Algorytmus
plot(df$race, df$risk_score)
#Einstufung:
#Caucasian:         ca. 3
#African-American:  ca. 5
#Hispanic:          ca. 3
#Asia:              ca. 2
#Native American:   ca. 7
#Other:             ca. 2

#African-American und Native American werden häufiger als höheres Risiko eingestuft und
#werden auch häufiger Rückfällig als die anderen.

plot(df$is_recid, df$race)
(100/6173)*3175
#Den größten Teil der Rückfälligen insgesamt sind die African-American wobei sie auch die
#größte Personenanzahl von 51% haben.

#########################################################

#Geschlecht vs. Rückfällig
plot(df$sex, df$is_recid)
#Durchschnitt:
#male:    ca. 50%
#female:  ca. 40%

#Geschlecht vs. Algorythmus
plot(df$sex, df$risk_score)
#Durchschnitt:
#male:    ca. 4 passt ca. weil 50% Rückfällig werden
#female:  ca. 4 wird gut vorrausgesagt mit 40% Rückfälligkeit

#############################################################

#Hypothesen:
#H1: Männer begehen öfter Straftaten als Frauen und werden auch häufiger Rückfällig.
#H2: African-American und Native American begehen öfter Straftaten und werden auch
  #häufiger Rückfällig.
#H3: Asiaten werden im Verhältnis am wenigsten Rückfällig.

##############################################################

# Schritt 2: Erstellen Sie ein Vorhersagemodell, ob eine Person rückfällig wird.
#            Verifizieren & interpretieren Sie das Modell und den Einfluss der Variablen.
#            Welche Variable wÃ¤ren bei einem perfekten Algorithmus signifikant?
#
#            Berechnen Sie auch anhand einiger typischer DatensÃ¤tze tatsÃ¤chliche
#            Wahrscheinlichkeiten und diskutieren deren Unterschiede.
describe(df)
model1 = glm(is_recid ~ age + charge_degree + race + sex + priors_count + risk_score, 
             data = df, family = binomial(link = "logit"))
summary(model1)

###########################_Model Tests_###############################
deviance(model1)/model1$df.residual
#Wert liegt mit 1.2 knapp über 1. Ist noch ok.

hinkley(model1)
#sieht nicht ok aus. Deutet auf eine fehlende Variable bzw. 
#eine nicht lineare Beziehung oder andere Probleme im Modell hin.

dfn = df
dfn$priors_count=dfn$priors_count+1
model1b = glm(is_recid ~ age + charge_degree + race + sex + priors_count + risk_score, 
             data = dfn, family = binomial(link = "logit"))
log.linearity.test(model1b)
#age und priors_count sind nicht ok. Könnten also eine lineare Abhängigkeit haben!

cor(df$age, df$age*as.integer(df$is_recid))
#Korrelation von 0.6
cor(df$priors_count, df$priors_count*as.integer(df$is_recid))
#Korrelation von 0.96

vif(model1)
#Alle Werte befinden sich unter 5, daher ist nur eine Geringe Abhängigkeit zu bemerken

#Einflussreiche Werte / Ausreißer
outlierTest(model1)
#Keine Ausreißer gefunden.
plot(model1, which=4)
#Keine Werte über 0.05
plot(model1, which=5) 
#Alle Datensätze innerhalb der roten Werte +-0.5 und +-1 ist gut.

ROC(model1)
#Die Erklärkraft unseres Modells könnte Besser sein. Eventuell hängt es mit der Kolinearität
#zusammen.

logisticR2(model1)

########################_Zurückrechnen und Interpretieren_###########################
summary(model1)

#Interpretation:
intcp = inv.logit(coef(model1)[1]) #--> diese liefert direkt die absolute Wahrscheinlichkeit
#Ergebniss: 0.50 = 50% Wahrscheinlichkeit

summary(df)
#Basisfall ist männlich, Caucasian, charge_degree mit F, mit einer 50% Wahrscheinlichkeit.
#Basisfall hat aber age = 0 was nicht sinnvoll wäre!

exp(coef(model1))
#Wenn man eine Frau ist verringert sich die Chance -35% Rückfällig zu werden.
#Wenn man ein Asia ist verringert sich die Chance -23% Rückfällig zu werden.
#Für jedes Jahr das man älter ist verringert sich die Chance um 3% Rückfällig zu werden.
#Für jeden priors_count erhöht sich die Chance um 13% Rückfällig zu werden.
#Für jede risk_score erhöht sich die Chance um 17% Rückfällig zu werden.
#Für charge_degree M sinkt die Chance um -11% Rückfällig zu werden.
#Bei allen Rassen sinkt die Chance außer bei African-American, dort steigts um 1%.

###########################Einfluss der Variablen################################
Anova(model1)
#priors_count hat höchten Einfluss.
#risk_score und age sagen auch viel aus.
#charge_degree, race und sex eher weniger.

drop1(model1)
#race verschlächtert sogar das Modell.

#risk_score müsste signifikant sein und andere Variablen nicht wenn risk_score richtig gut wäre.

################################Predict###########################################

table(df$race)
predict(model1, newdata = data.frame(sex=c("Male", "Female"), charge_degree ="F", age=35, race="African-American", priors_count=3, risk_score=4), type='response')
#African-American: male = 0.5, female = 0.40
predict(model1, newdata = data.frame(sex=c("Male", "Female"), charge_degree ="F", age=35, race="Caucasian", priors_count=3, risk_score=4), type='response')
#Caucasian: male = 0.5, female = 0.4
predict(model1, newdata = data.frame(sex=c("Male", "Female"), charge_degree ="F", age=35, race="Hispanic", priors_count=3, risk_score=4), type='response')
#Hispanic: male = 0.45, female = 0.35
predict(model1, newdata = data.frame(sex=c("Male", "Female"), charge_degree ="F", age=35, race="Other", priors_count=3, risk_score=4), type='response')
#Other: male = 0.47, female = 0.37

#Rasse sind alle ca. gleich.
#Frauen werden weniger Rückfällig obwohl sie gleich eingestuft werden.

# Schritt 3: Erstellen Sie ein weiteres Modell, das aus allen vorhandenen Variablen
#            (inkl. is_recid aber exkl. risk_score) versucht, vorherzusagen, ob der
#            Risikowert grÃ¶ÃŸergleich 7 ist oder nicht.
#            Verifizieren & interpretieren Sie das Modell und den Einfluss der Variablen.
#
# Hinweis: Sie erstellen also ein Modell, das versucht anhand der bekannten Variablen
#          und der -- zum Zeitpunkt der Berechnung des Risikowerts zukÃ¼nftigen -- RÃ¼ckfallquote,
#          das Ergebnis des Algorithmus vorherzusagen. Welche Variable wÃ¤ren bei einem
#          perfekten Algorithmus signifikant?
df$risk_score.new = ifelse(df$risk_score >= 7, 1, 0) #Größergleich 7 soll 1 sein sonst 0!

model2 = glm(risk_score.new ~ is_recid + age + charge_degree + race + sex + priors_count, 
             data = df, family = binomial(link = "logit"))
summary(model2)

###########################_Model Tests_###############################
deviance(model2)/model2$df.residual
#Wert liegt unter 1. Das ist gut.

hinkley(model2)
#sieht ok aus.

vif(model2)
#Alle Werte befinden sich unter 5, daher ist nur eine Geringe Abhängigkeit zu bemerken

#Einflussreiche Werte / Ausreißer
outlierTest(model2)
#Keine Ausreißer gefunden.
plot(model2, which=4)
#Keine Werte über 0.05
plot(model2, which=5) 
#Alle Datensätze innerhalb der roten Werte +-0.5 und +-1 ist gut.

ROC(model1)
ROC(model2)
#model2 hat einen größeren Bereich und sagt somit besser Vorraus.

########################_Zurückrechnen und Interpretieren_###########################
summary(model2)
#Wäre der Algorythmus perfekt dann wäre nur is_recid signifikant!

#Interpretation:
intcp = inv.logit(coef(model2)[1]) #--> diese liefert direkt die absolute Wahrscheinlichkeit
#Ergebniss: 0.64 = 64% Wahrscheinlichkeit

summary(df)
#Basisfall ist männlich, Caucasian, charge_degree mit F, mit einer 50% Wahrscheinlichkeit.
#Basisfall hat aber age = 0 was nicht sinnvoll wäre!

exp(coef(model2))
#Die Chance bei female sinkt um 5% das sie 7+ eingestuft wird.
#is_recid = yes steigt die Chance um 90% das man als 7+ eingestuft wird.
#Pro Jahr veringert sich die Chance um 10%.
#Wenn man African-American ist erhöht sich die Chance um 75% als 7+ eingestuft wird.
#priors_count als jede weitere Straftat erhöht die Chance um 24%.

# Schritt 4: Conclusio:
#            Was schlieÃŸen Sie aus den beiden Modellen?
#            Ist der Algorithmus (implizit) rassistisch bzw. sexistisch?
#            Falls nein, warum nicht? Falls ja, warum?
#            Gibt es EinschrÃ¤nkungen fÃ¼r die Interpretation?

cbind(coef(model1), coef(model2))


# Tipp fÃ¼r Interpretation: sehen Sie sich strafe-perfekter-score.R an,
# bevor Sie sich die MusterlÃ¶sung ansehen. Das sollte bei Interpretation helfen.


# Bei Interesse:
# Artikel: https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
# Methode: https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm
# Daten: https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb
